{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loan Fullfilment Prediction\n",
    "\n",
    "Use logistic regression to predict loan fullfillment probability. The definition of loan been NOT fullfilled is that it is not fully funded 60 days after original loand start date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine, Column, Integer, String, Table, MetaData\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "\n",
    "import pymysql\n",
    "pymysql.install_as_MySQLdb()\n",
    "\n",
    "from config import MYSQL_URL\n",
    "\n",
    "source_engine = create_engine(MYSQL_URL, encoding='utf-8')\n",
    "source_session = sessionmaker(source_engine)\n",
    "\n",
    "target_engine = create_engine(\"sqlite:///db/kiva.sqlite\")\n",
    "target_session = sessionmaker(target_engine)\n",
    "\n",
    "\n",
    "sqlite_conn = target_engine.connect()\n",
    "mysql_conn = source_engine.connect()\n",
    "\n",
    "metadata = MetaData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT \n",
    "    *\n",
    "FROM kiva.loan \n",
    "where\n",
    "    posted_time between '2017-06-01' and '2017-09-01'\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql(sql, mysql_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['loan_id', 'loan_name', 'original_language', 'description',\n",
       "       'description_translated', 'funded_amount', 'loan_amount', 'status',\n",
       "       'image_id', 'video_id', 'activity_name', 'sector_name', 'loan_use',\n",
       "       'country_code', 'country_name', 'town_name', 'currency_policy',\n",
       "       'currency_exchange_coverage_rate', 'currency', 'partner_id',\n",
       "       'posted_time', 'planned_expiration_time', 'disburse_time',\n",
       "       'raised_time', 'lender_term', 'num_lenders_total',\n",
       "       'num_journal_entries', 'num_bulk_entries', 'tags', 'borrower_names',\n",
       "       'borrower_genders', 'borrower_pictured', 'repayment_interval',\n",
       "       'distribution_model', 'gender'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictor Selection\n",
    "Observe the data and select fields which are either quantative or has limit amount of unique values. This model might be expanded to include more features later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['English', 'Spanish', 'French', 'Russian', 'Portuguese', None],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.original_language.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Agriculture', 'Food', 'Arts', 'Clothing', 'Education', 'Housing',\n",
       "       'Personal Use', 'Services', 'Transportation', 'Retail',\n",
       "       'Manufacturing', 'Construction', 'Health', 'Wholesale',\n",
       "       'Entertainment'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sector_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PH', 'KE', 'IN', 'JO', 'KH', 'TJ', 'PY', 'BO', 'SV', 'VN', 'GT',\n",
       "       'MG', 'XK', 'TR', 'NI', 'MX', 'ID', 'EC', 'SN', 'PK', 'RW', 'LB',\n",
       "       'AM', 'CO', 'PE', 'LA', 'UG', 'HT', 'LR', 'MZ', 'TG', 'CD', 'HN',\n",
       "       'MM', 'ZW', 'PS', 'NG', 'WS', 'GE', 'SB', 'MD', 'EG', 'TL', 'BF',\n",
       "       'SL', 'US', 'AL', 'TZ', 'CR', 'MW', 'ZM', 'CM', 'GH', 'UA', 'ML',\n",
       "       'NP', 'BR', 'LS', 'KG', 'YE', 'TH', 'PR', 'DO', 'IL', 'BT', 'SS',\n",
       "       'ZA'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.country_code.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Philippines', 'Kenya', 'India', 'Jordan', 'Cambodia',\n",
       "       'Tajikistan', 'Paraguay', 'Bolivia', 'El Salvador', 'Vietnam',\n",
       "       'Guatemala', 'Madagascar', 'Kosovo', 'Turkey', 'Nicaragua',\n",
       "       'Mexico', 'Indonesia', 'Ecuador', 'Senegal', 'Pakistan', 'Rwanda',\n",
       "       'Lebanon', 'Armenia', 'Colombia', 'Peru',\n",
       "       \"Lao People's Democratic Republic\", 'Uganda', 'Haiti', 'Liberia',\n",
       "       'Mozambique', 'Togo', 'The Democratic Republic of the Congo',\n",
       "       'Honduras', 'Myanmar (Burma)', 'Zimbabwe', 'Palestine', 'Nigeria',\n",
       "       'Samoa', 'Georgia', 'Solomon Islands', 'Moldova', 'Egypt',\n",
       "       'Timor-Leste', 'Burkina Faso', 'Sierra Leone', 'United States',\n",
       "       'Albania', 'Tanzania', 'Costa Rica', 'Malawi', 'Zambia',\n",
       "       'Cameroon', 'Ghana', 'Ukraine', 'Mali', 'Nepal', 'Brazil',\n",
       "       'Lesotho', 'Kyrgyzstan', 'Yemen', 'Thailand', 'Puerto Rico',\n",
       "       'Dominican Republic', 'Israel', 'Bhutan', 'South Sudan',\n",
       "       'South Africa'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.country_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 14.,   8.,  16.,  18.,  11.,  20.,  13.,  10.,  15.,  26.,  21.,\n",
       "        62.,  25.,  12.,  19.,   7.,   9.,  22.,  17.,   5.,  27.,   6.,\n",
       "        30.,   4.,  38.,  33.,  24.,  32.,  23.,  36.,  37.,  28.,  39.,\n",
       "        31.,  34.,  42.,  51.,  29.,  53.,  35.,  60.,   3.,  50.,  45.,\n",
       "        88., 115.,  48.,  40.,  41.,  95.,  98.,  59.,  56.,  43., 142.,\n",
       "        63.,  74.,  76.,  61., 134., 121., 113.,  75.,  86.,  44.,  57.,\n",
       "         2.,  67., 143., 109.,  83.,  49.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.lender_term.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['F', 'M', 'U'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.gender.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['irregular', 'monthly', 'bullet'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.repayment_interval.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['field_partner', 'direct'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.distribution_model.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2807 53970]\n"
     ]
    }
   ],
   "source": [
    "feature_names = [\n",
    "    'funded_amount',\n",
    "    'original_language',\n",
    "    'country_name',\n",
    "    'sector_name',\n",
    "    'lender_term',\n",
    "    'gender',\n",
    "    'repayment_interval',\n",
    "    'distribution_model',\n",
    "]\n",
    "\n",
    "X = df[feature_names]\n",
    "y = (df.loan_amount == df.funded_amount)\n",
    "\n",
    "X = pd.get_dummies(X)\n",
    "print(np.bincount(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['funded_amount', 'lender_term', 'original_language_English',\n",
       "       'original_language_French', 'original_language_Portuguese',\n",
       "       'original_language_Russian', 'original_language_Spanish',\n",
       "       'country_name_Albania', 'country_name_Armenia', 'country_name_Bhutan',\n",
       "       'country_name_Bolivia', 'country_name_Brazil',\n",
       "       'country_name_Burkina Faso', 'country_name_Cambodia',\n",
       "       'country_name_Cameroon', 'country_name_Colombia',\n",
       "       'country_name_Costa Rica', 'country_name_Dominican Republic',\n",
       "       'country_name_Ecuador', 'country_name_Egypt',\n",
       "       'country_name_El Salvador', 'country_name_Georgia',\n",
       "       'country_name_Ghana', 'country_name_Guatemala', 'country_name_Haiti',\n",
       "       'country_name_Honduras', 'country_name_India', 'country_name_Indonesia',\n",
       "       'country_name_Israel', 'country_name_Jordan', 'country_name_Kenya',\n",
       "       'country_name_Kosovo', 'country_name_Kyrgyzstan',\n",
       "       'country_name_Lao People's Democratic Republic', 'country_name_Lebanon',\n",
       "       'country_name_Lesotho', 'country_name_Liberia',\n",
       "       'country_name_Madagascar', 'country_name_Malawi', 'country_name_Mali',\n",
       "       'country_name_Mexico', 'country_name_Moldova',\n",
       "       'country_name_Mozambique', 'country_name_Myanmar (Burma)',\n",
       "       'country_name_Nepal', 'country_name_Nicaragua', 'country_name_Nigeria',\n",
       "       'country_name_Pakistan', 'country_name_Palestine',\n",
       "       'country_name_Paraguay', 'country_name_Peru',\n",
       "       'country_name_Philippines', 'country_name_Puerto Rico',\n",
       "       'country_name_Rwanda', 'country_name_Samoa', 'country_name_Senegal',\n",
       "       'country_name_Sierra Leone', 'country_name_Solomon Islands',\n",
       "       'country_name_South Africa', 'country_name_South Sudan',\n",
       "       'country_name_Tajikistan', 'country_name_Tanzania',\n",
       "       'country_name_Thailand',\n",
       "       'country_name_The Democratic Republic of the Congo',\n",
       "       'country_name_Timor-Leste', 'country_name_Togo', 'country_name_Turkey',\n",
       "       'country_name_Uganda', 'country_name_Ukraine',\n",
       "       'country_name_United States', 'country_name_Vietnam',\n",
       "       'country_name_Yemen', 'country_name_Zambia', 'country_name_Zimbabwe',\n",
       "       'sector_name_Agriculture', 'sector_name_Arts', 'sector_name_Clothing',\n",
       "       'sector_name_Construction', 'sector_name_Education',\n",
       "       'sector_name_Entertainment', 'sector_name_Food', 'sector_name_Health',\n",
       "       'sector_name_Housing', 'sector_name_Manufacturing',\n",
       "       'sector_name_Personal Use', 'sector_name_Retail',\n",
       "       'sector_name_Services', 'sector_name_Transportation',\n",
       "       'sector_name_Wholesale', 'gender_F', 'gender_M', 'gender_U',\n",
       "       'repayment_interval_bullet', 'repayment_interval_irregular',\n",
       "       'repayment_interval_monthly', 'distribution_model_direct',\n",
       "       'distribution_model_field_partner'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No need to scale Y as it is boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model Training and Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_test_matrix(y, predictions):\n",
    "    df = pd.DataFrame({\n",
    "        'y': y,\n",
    "        'predictions': predictions,\n",
    "        'value': [1] * len(y)\n",
    "    })\n",
    "    print(pd.pivot_table(df, index=['y'], columns=['predictions'], aggfunc=np.sum))\n",
    "    \n",
    "\n",
    "def run_classifier(classifier, X_train, y_train, X_test, y_test):\n",
    "    '''\n",
    "    Show Percentage of identifying funded and NOT funded correctly\n",
    "    '''\n",
    "    classifier.fit(X_train, y_train)\n",
    "    print(f\"Training Data Score: {classifier.score(X_train_scaled, y_train)}\")\n",
    "    \n",
    "    predictions = classifier.predict(X_train)\n",
    "    print('Evaluate Train Data Prediction Result: ')\n",
    "    print_test_matrix(y_train, predictions)\n",
    "   \n",
    "    print(f\"Testing Data Score: {classifier.score(X_test_scaled, y_test)}\")\n",
    "    predictions = classifier.predict(X_test)\n",
    "    print('Evaluate Test Data Prediction Result: ')\n",
    "    print_test_matrix(y_test, predictions)\n",
    "    \n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.9592008412197687\n",
      "Evaluate Train Data Prediction Result: \n",
      "            value       \n",
      "predictions False  True \n",
      "y                       \n",
      "False         407   1426\n",
      "True          126  36081\n",
      "Testing Data Score: 0.956663286545338\n",
      "Evaluate Test Data Prediction Result: \n",
      "            value       \n",
      "predictions False  True \n",
      "y                       \n",
      "False         234    740\n",
      "True           72  17691\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_classifier(classifier, X_train_scaled, y_train, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the result from logistic regression is not very precise as both type 1 error and type 2 error ratio is significant. This is likely contribute by all features are categorical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative Models\n",
    "We will try decision tree and randon forest, nural network, then compare the model accuracy and adopt the one with best prediction accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.9936908517350158\n",
      "Evaluate Train Data Prediction Result: \n",
      "            value       \n",
      "predictions False  True \n",
      "y                       \n",
      "False        1674    159\n",
      "True           81  36126\n",
      "Testing Data Score: 0.9616267278646529\n",
      "Evaluate Test Data Prediction Result: \n",
      "            value       \n",
      "predictions False  True \n",
      "y                       \n",
      "False         587    387\n",
      "True          332  17431\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf = run_classifier(clf, X_train_scaled, y_train, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result from decision tree model looks much better. However the model looks slighted overfitted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.9936908517350158\n",
      "Evaluate Train Data Prediction Result: \n",
      "            value       \n",
      "predictions False  True \n",
      "y                       \n",
      "False        1674    159\n",
      "True           81  36126\n",
      "Testing Data Score: 0.961893579548487\n",
      "Evaluate Test Data Prediction Result: \n",
      "            value       \n",
      "predictions False  True \n",
      "y                       \n",
      "False         576    398\n",
      "True          316  17447\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = tree.DecisionTreeClassifier()\n",
    "rf = clf.fit(X_train, y_train)\n",
    "run_classifier(rf, X_train_scaled, y_train, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nural Networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train_categorical = to_categorical(y_train)\n",
    "y_test_categorical = to_categorical(y_test)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=6, activation='relu', input_dim=2))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.45546311, -0.7963329 ,  0.58257142, ...,  0.98808361,\n",
       "        -0.10190879,  0.10190879],\n",
       "       [ 0.07110527,  0.14305206,  0.58257142, ..., -1.0120601 ,\n",
       "        -0.10190879,  0.10190879],\n",
       "       [-0.5699345 , -0.95289706,  0.58257142, ...,  0.98808361,\n",
       "        -0.10190879,  0.10190879],\n",
       "       ...,\n",
       "       [-0.45546311, -0.7963329 ,  0.58257142, ..., -1.0120601 ,\n",
       "        -0.10190879,  0.10190879],\n",
       "       [ 0.59767364,  0.14305206,  0.58257142, ...,  0.98808361,\n",
       "        -0.10190879,  0.10190879],\n",
       "       [-0.43256883, -0.7963329 ,  0.58257142, ..., -1.0120601 ,\n",
       "        -0.10190879,  0.10190879]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_7_input to have shape (2,) but got array with shape (97,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-48b0713203d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m )\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    953\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 955\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m    956\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    957\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    752\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    755\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    134\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    137\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected dense_7_input to have shape (2,) but got array with shape (97,)"
     ]
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
